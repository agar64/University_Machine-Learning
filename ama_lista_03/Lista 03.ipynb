{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e4e00c0-c3d5-4753-bace-6453a15bf768",
   "metadata": {},
   "source": [
    "## Machine Learning - Lista 3\n",
    "### Aluno: Douglas Gaspar Feitosa Freitas\n",
    "### Matrícula: 473552"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b24220-0f81-47c6-a2ff-3dc2b77f4da5",
   "metadata": {},
   "source": [
    "## Questão 1\n",
    "\n",
    "Considere o conjunto de dados disponível em **kc2.csv**, organizado em 22 colunas, sendo as 21 primeiras colunas os atributos e a última coluna a saída. Os 21 atributos são referentes à caracterização de códigos-fontes para processamento de dados na NASA. A saída é a indicação de ausência (0) ou existência (1) de defeitos (os dados foram balanceados via subamostragem). Maiores detalhes sobre os dados podem ser conferidos em *https://www.openml.org/search?type=data&sort=runs&id=1063&status=active*.\n",
    "\n",
    "a) Considerando uma validação cruzada em 10 folds, avalie modelos de classificação binária nos dados em questão. Para tanto, use as abordagens abaixo:\n",
    "- **KNN** (escolha k = 1 e k = 5, distância Euclidiana e Mahalonobis, totalizando 4 combinações);\n",
    "- **Árvore de Decisão** (você pode usar uma implementação já existente, como a do scikit-learn, com índices de impureza de gini e entropia).\n",
    " \n",
    "b) Para cada modelo criado, reporte valor médio e desvio padrão das métricas de **acurácia**, **revocação**, **precisão** e **F1-score**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9631c132-2789-400c-bdf2-7c99261cdad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(213, 21)\n",
      "(213, 1)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Carregar o dataset kc2.csv\n",
    "dataset = pd.read_csv('kc2.csv')\n",
    "\n",
    "# Separar atributos (X) e a variável alvo (y)\n",
    "X = dataset.iloc[:, :-1].values  # todas as colunas menos a última\n",
    "y = dataset.iloc[:,-1:].values   # última coluna\n",
    "\n",
    "# Conferir formatos\n",
    "print(X.shape)\n",
    "print(y.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f30f04d-25ff-4d52-9fbc-105bea87044a",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "776617c9-efe0-4310-ba82-4bbfcc055040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN_k=1_euclidean:\n",
      "  Acurácia média = 0.6794, Desvio padrão = 0.1456\n",
      "  Precisão média = 0.6711, Desvio padrão = 0.1703\n",
      "  Revocação média = 0.6655, Desvio padrão = 0.2249\n",
      "  F1-score média = 0.6584, Desvio padrão = 0.2044\n",
      "\n",
      "KNN_k=1_mahalanobis:\n",
      "  Acurácia média = 0.6513, Desvio padrão = 0.1644\n",
      "  Precisão média = 0.6099, Desvio padrão = 0.2387\n",
      "  Revocação média = 0.6464, Desvio padrão = 0.2615\n",
      "  F1-score média = 0.6233, Desvio padrão = 0.2417\n",
      "\n",
      "KNN_k=5_euclidean:\n",
      "  Acurácia média = 0.7727, Desvio padrão = 0.1872\n",
      "  Precisão média = 0.7039, Desvio padrão = 0.2770\n",
      "  Revocação média = 0.7427, Desvio padrão = 0.3447\n",
      "  F1-score média = 0.7152, Desvio padrão = 0.3098\n",
      "\n",
      "KNN_k=5_mahalanobis:\n",
      "  Acurácia média = 0.7305, Desvio padrão = 0.1534\n",
      "  Precisão média = 0.7724, Desvio padrão = 0.2779\n",
      "  Revocação média = 0.6018, Desvio padrão = 0.2754\n",
      "  F1-score média = 0.6555, Desvio padrão = 0.2606\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "# Função para calcular a distância entre dois pontos (Euclidiana e Mahalanobis)\n",
    "def calculate_distance(X_train, X_test, metric='euclidean', VI=None):\n",
    "    if metric == 'euclidean':\n",
    "        return cdist(X_test, X_train, metric='euclidean')\n",
    "    elif metric == 'mahalanobis':\n",
    "        return cdist(X_test, X_train, metric='mahalanobis', VI=VI)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported metric\")\n",
    "\n",
    "# Implementação do KNN manual\n",
    "def knn_predict(X_train, y_train, X_test, k=1, metric='euclidean'):\n",
    "    if metric == 'mahalanobis':\n",
    "        VI = np.linalg.inv(np.cov(X_train.T))\n",
    "        distances = calculate_distance(X_train, X_test, metric='mahalanobis', VI=VI)\n",
    "    else:\n",
    "        distances = calculate_distance(X_train, X_test, metric='euclidean')\n",
    "    \n",
    "    # Para cada ponto de teste, encontrar os k vizinhos mais próximos\n",
    "    neighbors_idx = np.argsort(distances, axis=1)[:, :k]\n",
    "    neighbors_labels = y_train[neighbors_idx]\n",
    "    \n",
    "    # Prever a classe mais comum entre os vizinhos (corrigido)\n",
    "    y_pred = [Counter(neighbors.flatten()).most_common(1)[0][0] for neighbors in neighbors_labels]\n",
    "    return np.array(y_pred)\n",
    "\n",
    "# Função para rodar a validação cruzada manualmente\n",
    "def cross_validate_knn(X, y, k=1, metric='euclidean', n_splits=10):\n",
    "    skf = StratifiedKFold(n_splits=n_splits)\n",
    "    \n",
    "    accuracies, precisions, recalls, f1s = [], [], [], []\n",
    "    \n",
    "    for train_idx, test_idx in skf.split(X, y):\n",
    "        X_train, X_test = X[train_idx], X[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "        \n",
    "        y_pred = knn_predict(X_train, y_train, X_test, k=k, metric=metric)\n",
    "        \n",
    "        # Calcular as métricas\n",
    "        accuracies.append(accuracy_score(y_test, y_pred))\n",
    "        precisions.append(precision_score(y_test, y_pred))\n",
    "        recalls.append(recall_score(y_test, y_pred))\n",
    "        f1s.append(f1_score(y_test, y_pred))\n",
    "    \n",
    "    # Retornar as métricas médias e desvio padrão\n",
    "    return {\n",
    "        'accuracy_mean': np.mean(accuracies), 'accuracy_std': np.std(accuracies),\n",
    "        'precision_mean': np.mean(precisions), 'precision_std': np.std(precisions),\n",
    "        'recall_mean': np.mean(recalls), 'recall_std': np.std(recalls),\n",
    "        'f1_mean': np.mean(f1s), 'f1_std': np.std(f1s)\n",
    "    }\n",
    "\n",
    "# Testando KNN com k=1 e k=5 usando a distância Euclidiana e Mahalanobis\n",
    "results_knn_manual = {}\n",
    "for k in [1, 5]:\n",
    "    for metric in ['euclidean', 'mahalanobis']:\n",
    "        results = cross_validate_knn(X, y, k=k, metric=metric)\n",
    "        results_knn_manual[f'KNN_k={k}_{metric}'] = results\n",
    "\n",
    "# Exibir resultados KNN\n",
    "for key, value in results_knn_manual.items():\n",
    "    print(f\"{key}:\")\n",
    "    print(f\"  Acurácia média = {value['accuracy_mean']:.4f}, Desvio padrão = {value['accuracy_std']:.4f}\")\n",
    "    print(f\"  Precisão média = {value['precision_mean']:.4f}, Desvio padrão = {value['precision_std']:.4f}\")\n",
    "    print(f\"  Revocação média = {value['recall_mean']:.4f}, Desvio padrão = {value['recall_std']:.4f}\")\n",
    "    print(f\"  F1-score média = {value['f1_mean']:.4f}, Desvio padrão = {value['f1_std']:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3f08ef-127f-4f17-b1e2-277724440ec8",
   "metadata": {},
   "source": [
    "### Árvore de Decisão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2d4e2b21-0be6-48f5-9b26-107bc80f24b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTree_gini:\n",
      "  Acurácia média = 0.7273, Desvio padrão = 0.1047\n",
      "  Precisão média = 0.7274, Desvio padrão = 0.1424\n",
      "  Revocação média = 0.6945, Desvio padrão = 0.2354\n",
      "  F1-score média = 0.6948, Desvio padrão = 0.1904\n",
      "\n",
      "DecisionTree_entropy:\n",
      "  Acurácia média = 0.7171, Desvio padrão = 0.1260\n",
      "  Precisão média = 0.6896, Desvio padrão = 0.2376\n",
      "  Revocação média = 0.6745, Desvio padrão = 0.2688\n",
      "  F1-score média = 0.6710, Desvio padrão = 0.2377\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Função para rodar validação cruzada na árvore de decisão\n",
    "def cross_validate_decision_tree(X, y, impurity_func, max_depth=5, n_splits=10):\n",
    "    skf = StratifiedKFold(n_splits=n_splits)\n",
    "    \n",
    "    accuracies, precisions, recalls, f1s = [], [], [], []\n",
    "    \n",
    "    for train_idx, test_idx in skf.split(X, y):\n",
    "        X_train, X_test = X[train_idx], X[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "        \n",
    "        tree = build_tree(X_train, y_train, impurity_func, max_depth=max_depth)\n",
    "        \n",
    "        y_pred = [predict_tree(tree, x) for x in X_test]\n",
    "        \n",
    "        # Calcular as métricas\n",
    "        accuracies.append(accuracy_score(y_test, y_pred))\n",
    "        precisions.append(precision_score(y_test, y_pred, zero_division=0))\n",
    "        recalls.append(recall_score(y_test, y_pred, zero_division=0))\n",
    "        f1s.append(f1_score(y_test, y_pred, zero_division=0))\n",
    "    \n",
    "    return {\n",
    "        'accuracy_mean': np.mean(accuracies), 'accuracy_std': np.std(accuracies),\n",
    "        'precision_mean': np.mean(precisions), 'precision_std': np.std(precisions),\n",
    "        'recall_mean': np.mean(recalls), 'recall_std': np.std(recalls),\n",
    "        'f1_mean': np.mean(f1s), 'f1_std': np.std(f1s)\n",
    "    }\n",
    "\n",
    "# Testar árvore de decisão com gini e entropia\n",
    "results_dt = {}\n",
    "for impurity_func, name in [(gini_impurity, 'gini'), (entropy_impurity, 'entropy')]:\n",
    "    results = cross_validate_decision_tree(X, y, impurity_func)\n",
    "    results_dt[f'DecisionTree_{name}'] = results\n",
    "\n",
    "# Exibir resultados Árvore de Decisão\n",
    "for key, value in results_dt.items():\n",
    "    print(f\"{key}:\")\n",
    "    print(f\"  Acurácia média = {value['accuracy_mean']:.4f}, Desvio padrão = {value['accuracy_std']:.4f}\")\n",
    "    print(f\"  Precisão média = {value['precision_mean']:.4f}, Desvio padrão = {value['precision_std']:.4f}\")\n",
    "    print(f\"  Revocação média = {value['recall_mean']:.4f}, Desvio padrão = {value['recall_std']:.4f}\")\n",
    "    print(f\"  F1-score média = {value['f1_mean']:.4f}, Desvio padrão = {value['f1_std']:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0081f05-6835-4084-96c1-5957b3d0b5f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
